# RobustnessPrivacyTradeoffInBNNs
This repository contains my MEng Machine Learning master's thesis work at Imperial College London. It explores the connection between adversarial robustness, differential privacy and uncertainty quantification in Bayesian Neural Networks with a particular focus on the Hamiltonian Monte Carlo probabilistic inference technique. For each dataset presented, experiments involving the training of 5 neural network with different optimizers are presented: Vanilla Stochastic Gradient Descent (SGD), Hamiltonian Monte Carlo (HMC), Differentially Private HMC (HMC-DP), IBP (interval bound propagation) trained HMC (ADV-HMC) and ADV-DP-HMC, showing that it is possible to achieve simultaneously be robust, private and achieve good uncertainty quantification. Baseline results for different adversarial training methods (Vanilla SGD, Vanilla HMC and HMC trained with FGSM, PGD and IBP) are also included to show comparable results to SOTA.    
